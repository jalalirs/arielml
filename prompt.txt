Project Summary: Ariel Exoplanet Data Challenge
This document outlines the problem statement, our current progress, and the architecture of our solution for the "Ariel Data Challenge 2025".

1. The Problem Statement
The core objective is to analyze simulated data from the ESA Ariel space telescope to recover the atmospheric transmission spectra of exoplanets.

Goal: For each exoplanet, we must predict its spectrum (the amount of starlight its atmosphere blocks at different wavelengths) and our uncertainty for that prediction.

Input Data: We are given raw, time-series image data from two different instruments: AIRS-CH0 (a spectrometer) and FGS1 (a photometer).

Core Challenge: The faint signal from the exoplanet's atmosphere is buried in significant noise from the telescope's electronics, cosmic rays, and the natural variability of the host star. Our task is to build a robust pipeline to clean this data and isolate the true signal.

2. Our Approach & Architecture
We have adopted a professional, modular approach to solve this problem, focusing on scalability, performance, and interpretability.

Modular Library (arielml): All core logic is being built into a custom, installable Python library.

Object-Oriented Pipeline: We created a central DataObservation class that encapsulates all data and processing logic for a single observation.

High-Performance Backend: The library features a backend-agnostic design that can run all numerical operations on either a CPU (NumPy) or a GPU (CuPy).

Interactive Visualization Tool: We built a sophisticated GUI application, the Data Inspector, using PyQt6 for interactively exploring the data and visualizing the impact of each processing step.

3. Current Progress: Data Reduction Complete
We have successfully built and debugged the entire data reduction pipeline, from raw images to clean, flattened, and phase-folded light curves. Our arielml library now includes robust, GPU-accelerated modules for:

Calibration: Full instrument calibration (ADC, masking, linearity, dark current, CDS, flat fielding).

Photometry: Aperture photometry with spatial and temporal sigma clipping to reject cosmic rays and outliers. The logic correctly handles both spectrometer (AIRS-CH0) and photometer (FGS1) data.

Detrending: A modular detrending framework with Polynomial and Savitzky-Golay models to remove instrumental noise and stellar variability.

Analysis: A phase-folding and binning module to average out random noise and reveal the final transit signal.

Our Data Inspector tool is complete and allows us to visualize every step of this process.

4. Project File Structure
Our project is organized into the following structure:

.
├── arielml/
├── utils.py
├── backend.py
├── config.py
├── data
│   ├── calibration.py
│   ├── detrending.py
│   ├── __init__.py
│   ├── loaders.py
│   ├── observation.py
│   └── photometry.py
│   └── analysis.py
├── evaluation
│   ├── __init__.py
│   └── metrics.py
├── __init__.py
├── models
│   ├── base.py
│   ├── cnn.py
│   ├── __init__.py
│   └── lgbm.py
└── pipelines
    ├── __init__.py
    ├── predict.py
    └── train.py
├── dataset
│   ├── adc_info.csv
│   ├── axis_info.parquet
│   ├── sample_submission.csv
│   ├── test
│   │   └── 1103775
│   │       ├── AIRS-CH0_calibration_0
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── AIRS-CH0_calibration_1
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── AIRS-CH0_signal_0.parquet
│   │       ├── AIRS-CH0_signal_1.parquet
│   │       ├── FGS1_calibration_0
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── FGS1_calibration_1
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── FGS1_signal_0.parquet
│   │       └── FGS1_signal_1.parquet
│   ├── test_star_info.csv
│   ├── train
│   │   ├── 1010375142
│   │   │   ├── AIRS-CH0_calibration_0
│   │   │   │   ├── dark.parquet
│   │   │   │   ├── dead.parquet
│   │   │   │   ├── flat.parquet
│   │   │   │   ├── linear_corr.parquet
│   │   │   │   └── read.parquet
│   │   │   ├── AIRS-CH0_signal_0.parquet
│   │   │   ├── FGS1_calibration_0
│   │   │   │   ├── dark.parquet
│   │   │   │   ├── dead.parquet
│   │   │   │   ├── flat.parque

│   │   │   │   ├── linear_corr.parquet
│   │   │   │   └── read.parquet
│   │   │   └── FGS1_signal_0.parquet
│   │   ├── 1024292144
│   │   │   ├── AIRS-CH0_calibration_0
│   │   │   │   ├── dark.parquet
│   │   │   │   ├── dead.parquet
│   │   │   │   ├── flat.parquet
│   │   │   │   ├── linear_corr.parquet
│   │   │   │   └── read.parquet
│   │   │   ├── AIRS-CH0_signal_0.parquet
│   │   │   ├── FGS1_calibration_0
│   │   │   │   ├── dark.parquet
│   │   │   │   ├── dead.parquet
│   │   │   │   ├── flat.parquet
│   │   │   │   ├── linear_corrparquet
│   │   │   │   └── read.parquet
│   │   │   └── FGS1_signal_0.parquet
.
.
.
│   │   └── 990959761
│   │       ├── AIRS-CH0_calibration_0
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── AIRS-CH0_signal_0.parquet
│   │       ├── FGS1_calibration_0
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       └── FGS1_signal_0.parquet
│   ├── train.csv
│   ├── train_star_info.csv
│   └── wavelengths.csv
├── notebooks
│   ├── 01_data_exploration.ipynb
│   ├── 02_model_prototyping.ipynb
│   └── submission.ipynb
├── output
│   ├── figures
│   ├── models
│   └── submission.csv
├── README.md
├── requirements.txt
├── setup.py
├── tools
│   ├── data_inspector.py
│   └── results_visualizer.py
└── tree.txt




5. Next Steps
With the data processing pipeline complete and validated, we are now ready to move on to the final stage of the project: Machine Learning.

The next logical step is to build the models that will take our clean, detrended light curves and predict the final transit spectrum. This involves:

Enhance Detrending Models: Implement a more sophisticated Gaussian Process (GP) model in our detrending framework. This will provide a powerful alternative and allow for robust uncertainty estimation.

Feature Engineering: Extracting features from the final light curves (e.g., the transit depth at each wavelength).

Model Implementation: Building our first predictive model (e.g., LightGBM) in the arielml/models/ directory.

Custom Loss Function: Creating a custom loss function that directly optimizes for the competition's Gaussian Log-Likelihood (GLL) metric.

Training & Prediction Pipelines: Implementing the end-to-end scripts in arielml/pipelines/ to train our models and generate the submission.csv file.