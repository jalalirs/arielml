Project Summary: Ariel Exoplanet Data Challenge
This document outlines the problem statement, our current progress, and the architecture of our solution for the "Ariel Data Challenge 2025".

1. The Problem Statement
The core objective is to analyze simulated data from the ESA Ariel space telescope to recover the atmospheric transmission spectra of exoplanets.

Goal: For each exoplanet, we must predict its spectrum (the amount of starlight its atmosphere blocks at different wavelengths) and our uncertainty for that prediction.

Input Data: We are given raw, time-series image data from two different instruments: AIRS-CH0 (a spectrometer) and FGS1 (a photometer).

Core Challenge: The faint signal from the exoplanet's atmosphere is buried in significant noise from the telescope's electronics, cosmic rays, and the natural variability of the host star. Our task is to build a robust pipeline to clean this data and isolate the true signal.

2. Our Approach & Architecture
We have adopted a professional, modular approach to solve this problem, focusing on scalability, performance, and interpretability.

Modular Library (arielml): All core logic is being built into a custom, installable Python library.

Object-Oriented Pipeline: We created a central DataObservation class that encapsulates all data and processing logic for a single observation.

High-Performance Backend: The library features a backend-agnostic design that can run all numerical operations on either a CPU (NumPy) or a GPU (CuPy).

Interactive Visualization Tool: We built a sophisticated GUI application, the Data Inspector, using PyQt6 for interactively exploring the data and visualizing the impact of each processing step.

3. Current Progress: Advanced Detrending Complete
We have successfully built and debugged the entire data reduction pipeline. After identifying and fixing critical bugs in the calibration and transit mask calculations, we have moved beyond simple detrending and implemented a suite of advanced, physically-motivated models.

Our arielml library now includes a robust, modular detrending framework with the following models:

Baseline Models:

PolynomialDetrender: A simple polynomial fit to the out-of-transit data.

SavGolDetrender: Uses a Savitzky-Golay filter to smooth the light curve.

Advanced Gaussian Process (GP) Models:

GPDetrender: A per-wavelength GP model using the george library for robust CPU-based modeling.

GPyTorchDetrender: A high-performance, per-wavelength GP model built with gpytorch for full GPU acceleration.

Physically-Motivated Hybrid Model:

HybridDetrender: Inspired by winning approaches from previous competitions, this model first isolates and removes the common-mode 1D temporal drift across all wavelengths using a GP (CPU or GPU). It then models the remaining per-wavelength residuals with a simple polynomial. This provides a powerful method for handling shared instrumental noise.

Our Data Inspector tool is complete and allows for the interactive selection and comparison of all these detrending models on both CPU and GPU backends, providing immediate visual feedback on their performance.

4. Project File Structure
Our project is organized into the following structure:

.
├── arielml/
├── utils.py
├── backend.py
├── config.py
├── data
│   ├── calibration.py
│   ├── detrending.py
│   ├── __init__.py
│   ├── loaders.py
│   ├── observation.py
│   └── photometry.py
│   └── analysis.py
├── evaluation
│   ├── __init__.py
│   └── metrics.py
├── __init__.py
├── models
│   ├── base.py
│   ├── cnn.py
│   ├── __init__.py
│   └── lgbm.py
└── pipelines
    ├── __init__.py
    ├── predict.py
    └── train.py
├── dataset
│   ├── adc_info.csv
│   ├── axis_info.parquet
│   ├── sample_submission.csv
│   ├── test
│   │   └── 1103775
│   │       ├── AIRS-CH0_calibration_0
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── AIRS-CH0_calibration_1
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── AIRS-CH0_signal_0.parquet
│   │       ├── AIRS-CH0_signal_1.parquet
│   │       ├── FGS1_calibration_0
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── FGS1_calibration_1
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── FGS1_signal_0.parquet
│   │       └── FGS1_signal_1.parquet
│   ├── test_star_info.csv
│   ├── train
│   │   ├── 1010375142
│   │   │   ├── AIRS-CH0_calibration_0
│   │   │   │   ├── dark.parquet
│   │   │   │   ├── dead.parquet
│   │   │   │   ├── flat.parquet
│   │   │   │   ├── linear_corr.parquet
│   │   │   │   └── read.parquet
│   │   │   ├── AIRS-CH0_signal_0.parquet
│   │   │   ├── FGS1_calibration_0
│   │   │   │   ├── dark.parquet
│   │   │   │   ├── dead.parquet
│   │   │   │   ├── flat.parque

│   │   │   │   ├── linear_corr.parquet
│   │   │   │   └── read.parquet
│   │   │   └── FGS1_signal_0.parquet
│   │   ├── 1024292144
│   │   │   ├── AIRS-CH0_calibration_0
│   │   │   │   ├── dark.parquet
│   │   │   │   ├── dead.parquet
│   │   │   │   ├── flat.parquet
│   │   │   │   ├── linear_corr.parquet
│   │   │   │   └── read.parquet
│   │   │   ├── AIRS-CH0_signal_0.parquet
│   │   │   ├── FGS1_calibration_0
│   │   │   │   ├── dark.parquet
│   │   │   │   ├── dead.parquet
│   │   │   │   ├── flat.parquet
│   │   │   │   ├── linear_corrparquet
│   │   │   │   └── read.parquet
│   │   │   └── FGS1_signal_0.parquet
.
.
.
│   │   └── 990959761
│   │       ├── AIRS-CH0_calibration_0
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       ├── AIRS-CH0_signal_0.parquet
│   │       ├── FGS1_calibration_0
│   │       │   ├── dark.parquet
│   │       │   ├── dead.parquet
│   │       │   ├── flat.parquet
│   │       │   ├── linear_corr.parquet
│   │       │   └── read.parquet
│   │       └── FGS1_signal_0.parquet
│   ├── train.csv
│   ├── train_star_info.csv
│   └── wavelengths.csv
├── notebooks
│   ├── 01_data_exploration.ipynb
│   ├── 02_model_prototyping.ipynb
│   └── submission.ipynb
├── output
│   ├── figures
│   ├── models
│   └── submission.csv
├── README.md
├── requirements.txt
├── setup.py
├── tools
│   ├── data_inspector.py
│   └── results_visualizer.py
└── tree.txt




5. Next Steps
With a robust and flexible data processing pipeline now validated, we are ready to move on to the final stage of the project: Machine Learning.

The next logical steps are to build the models that will take our clean, detrended light curves and predict the final transit spectrum. This involves:

Feature Engineering: Extracting the final transit depths (and their uncertainties) from the light curves produced by our best detrending models (e.g., the HybridDetrender). This will form the feature set for our predictive models.

Model Implementation: Building our first predictive models (e.g., LightGBM, a simple MLP) within the arielml/models/ directory.

Custom Loss Function: Creating a custom loss function that directly optimizes for the competition's Gaussian Log-Likelihood (GLL) metric.

Training & Prediction Pipelines: Implementing the end-to-end scripts in arielml/pipelines/ to train our models on the training set and generate the final submission.csv file for the test set.

